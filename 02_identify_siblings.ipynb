{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and store sibling mentions, using the criteria determined by text analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import logging,sys\n",
    "from getpass import getpass \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['April10_1a',\n",
       " 'April10_1b',\n",
       " 'April10_1c',\n",
       " 'April10_2.json',\n",
       " 'April10_3a.txt',\n",
       " 'April10_3b.json',\n",
       " 'April10_4a',\n",
       " 'April10_4b',\n",
       " 'April10_4c',\n",
       " 'April10_5a',\n",
       " 'April10_5b',\n",
       " 'April10_5c',\n",
       " 'April10_5d',\n",
       " 'April10_5e',\n",
       " 'April10_5f',\n",
       " 'April10_5g',\n",
       " 'April10_5h',\n",
       " 'April10_5i',\n",
       " 'April11.json',\n",
       " 'April9.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "datfiles = [f for f in files if 'April' in f]\n",
    "datfiles\n",
    "#files in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irrel_hashtags = ['#equalpayday', '#tuesdaythoughts', '#lifecourbeeasier', '#zuckerberg', \\\n",
    "                  '#brochure', '#rack', '#flyer', '#roll',\\\n",
    "                 '#cbx_bloomingdays', '#felizmartes', '#temblor', '#mondaymotivation', \\\n",
    "                 '#americanidol', '#foodasitcom', '#michaelcohen', '#fcbsfc', '#fft18', '#michaelcohen',\\\n",
    "                 \"#onlychild\"]\n",
    "irrel_keywords=['research', 'keyword', 'market','digit'] \n",
    "irrel = irrel_hashtags + irrel_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the file being processed is April10_1a\n",
      "Now there are 2699 tweets.\n",
      "Now the file being processed is April10_1b\n",
      "Now there are 4993 tweets.\n",
      "Now the file being processed is April10_1c\n",
      "Now there are 6901 tweets.\n",
      "Now the file being processed is April10_2.json\n",
      "Now there are 9358 tweets.\n",
      "Now the file being processed is April10_3a.txt\n",
      "Now there are 9358 tweets.\n",
      "Now the file being processed is April10_3b.json\n",
      "Now there are 9358 tweets.\n",
      "Now the file being processed is April10_4a\n",
      "Now there are 10494 tweets.\n",
      "Now the file being processed is April10_4b\n",
      "Now there are 11699 tweets.\n",
      "Now the file being processed is April10_4c\n",
      "Now there are 12630 tweets.\n",
      "Now the file being processed is April10_5a\n",
      "Now there are 13725 tweets.\n",
      "Now the file being processed is April10_5b\n",
      "Now there are 14852 tweets.\n",
      "Now the file being processed is April10_5c\n",
      "Now there are 16121 tweets.\n",
      "Now the file being processed is April10_5d\n",
      "Now there are 17389 tweets.\n",
      "Now the file being processed is April10_5e\n",
      "Now there are 18651 tweets.\n",
      "Now the file being processed is April10_5f\n",
      "Now there are 19862 tweets.\n",
      "Now the file being processed is April10_5g\n",
      "Now there are 21090 tweets.\n",
      "Now the file being processed is April10_5h\n",
      "Now there are 22262 tweets.\n",
      "Now the file being processed is April10_5i\n",
      "Now there are 23029 tweets.\n",
      "Now the file being processed is April11.json\n",
      "Now there are 24009 tweets.\n",
      "Now the file being processed is April9.json\n",
      "Now there are 24031 tweets.\n"
     ]
    }
   ],
   "source": [
    "tweets_c = []\n",
    "for fname in datfiles:\n",
    "    print(\"Now the file being processed is\", fname)\n",
    "    with open(fname, 'r') as f:\n",
    "        my_tweets = json.load(f)\n",
    "    if my_tweets[-1] is None:\n",
    "        del my_tweets[-1]\n",
    "    for a_tweet in my_tweets:\n",
    "        if 'lang' in a_tweet:\n",
    "            if a_tweet['lang']!='en':  #filtering out all the non-english tweets\n",
    "                continue\n",
    "        if 'retweeted_status' in a_tweet: #filtering out retweets\n",
    "            continue  \n",
    "        if 'entities' not in a_tweet:\n",
    "            continue\n",
    "        if len(a_tweet['entities']['user_mentions'])==0:\n",
    "            continue  #filter out tweets where there were no mentions\n",
    "        if 'extended_tweet' in a_tweet:\n",
    "            text = a_tweet[\"extended_tweet\"][\"full_text\"] #full text of truncated tweets\n",
    "        elif 'text' in a_tweet:\n",
    "            text = a_tweet[\"text\"]\n",
    "        if any(word in text.lower() for word in irrel):  #filter out tweets with irrelevant hashtags or keywords\n",
    "            continue\n",
    "        tweets_c.append(a_tweet)\n",
    "    print(\"Now there are\", len(tweets_c), \"tweets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this step I got 24,031 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store these 24,031 twitter objects for future use\n",
    "with open('sibling_tweets_raw.txt', 'w') as outfile:\n",
    "    json.dump(tweets_c, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then get the tweet id, the username, the tweet, and the user mentions from these twitter objects. For the ease of processing in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweet_obj_c=[]\n",
    "for a_tweet in tweets_c:\n",
    "    a_tweet_dict={}\n",
    "    a_tweet_dict['id_str'] = a_tweet['id_str']\n",
    "    a_tweet_dict['screen_name'] = a_tweet['user']['screen_name']\n",
    "    if 'extended_tweet' in a_tweet:\n",
    "        a_tweet_dict['text']= a_tweet[\"extended_tweet\"][\"full_text\"]\n",
    "    elif 'text' in a_tweet:\n",
    "        a_tweet_dict['text']=a_tweet[\"text\"]\n",
    "    usermention = []\n",
    "    for mentions in a_tweet['entities']['user_mentions']: #note that some tweets can have multiple mentions\n",
    "        usermention.append(mentions['screen_name'])\n",
    "    a_tweet_dict['user_mentions'] = usermention\n",
    "    tweet_obj_c.append(a_tweet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_str': '983557792014393344',\n",
       " 'screen_name': 'CarlHLam',\n",
       " 'text': '@WGRZ It is so rare that we’re all together and yes, we’ve established that I’m the tallest. #NationalSiblingsDay #BeOn2 https://t.co/aC9nXcvmgj',\n",
       " 'user_mentions': ['WGRZ']}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_obj_c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store these shortened twitter objects\n",
    "with open('sibling_tweets_short.txt', 'w') as outfile:\n",
    "    json.dump(tweet_obj_c, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24031\n"
     ]
    }
   ],
   "source": [
    "#check length of it to make sure it's consistent with what's read in R\n",
    "print(len(tweet_obj_c))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
